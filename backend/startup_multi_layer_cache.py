#!/usr/bin/env python3
"""
Multi-Layer Cache Architecture Demonstration
æ™ºé˜…3.0å¤šå±‚ç¼“å­˜æ¶æ„æ¼”ç¤ºå¯åŠ¨è„šæœ¬
"""

import asyncio
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from services.cache_manager import CacheManager
from services.distributed_cache import DistributedCache, CacheConfig
from services.edge_cache import EdgeCache, CDNConfig, CDNProvider
from services.cache_consistency import CacheSystemManager, ConsistencyLevel
from database.enhanced_connection_manager import EnhancedConnectionManager, DatabaseRole
from database.query_optimizer import QueryOptimizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultiLayerCacheDemo:
    """å¤šå±‚ç¼“å­˜æ¶æ„æ¼”ç¤º"""
    
    def __init__(self):
        self.l1_cache = None
        self.l2_cache = None
        self.l3_cache = None
        self.cache_system_manager = None
        self.db_manager = None
        self.query_optimizer = None
        
    async def initialize_system(self):
        """åˆå§‹åŒ–å¤šå±‚ç¼“å­˜ç³»ç»Ÿ"""
        print("ğŸš€ Initializing Multi-Layer Cache Architecture...")
        
        # 1. åˆå§‹åŒ–L1åº”ç”¨ç¼“å­˜
        print("ğŸ“± Setting up L1 Application Cache...")
        self.l1_cache = CacheManager(
            cache_configs={
                'user_data': {'max_size': 1000, 'ttl': 300},
                'exam_data': {'max_size': 500, 'ttl': 600},
                'grading_results': {'max_size': 2000, 'ttl': 1800}
            }
        )
        
        # 2. åˆå§‹åŒ–L2åˆ†å¸ƒå¼ç¼“å­˜
        print("ğŸŒ Setting up L2 Distributed Cache...")
        redis_config = CacheConfig(
            host='localhost',
            port=6379,
            db=1,
            max_connections=10,
            cluster_nodes=[],
            enable_cluster=False
        )
        self.l2_cache = DistributedCache(config=redis_config, cache_prefix="zhiyue3_l2")
        await self.l2_cache.__aenter__()
        
        # 3. åˆå§‹åŒ–L3è¾¹ç¼˜ç¼“å­˜
        print("ğŸŒ Setting up L3 Edge Cache...")
        cdn_config = CDNConfig(
            provider=CDNProvider.LOCAL,
            endpoint="http://localhost:8080"
        )
        self.l3_cache = EdgeCache(
            cache_dir="./cache/edge_demo",
            max_size_gb=1.0,
            cdn_config=cdn_config
        )
        await self.l3_cache.__aenter__()
        
        # 4. åˆå§‹åŒ–ç¼“å­˜ä¸€è‡´æ€§ç®¡ç†å™¨
        print("ğŸ”„ Setting up Cache Consistency Manager...")
        self.cache_system_manager = CacheSystemManager()
        
        cache_config = {
            'cache_relationships': {
                'l1_cache': ['l2_cache'],
                'l2_cache': ['l3_cache'],
                'database': ['l1_cache', 'l2_cache']
            },
            'invalidation_patterns': {
                'users': ['user:*', 'profile:*', 'session:*'],
                'exams': ['exam:*', 'question:*'],
                'grading': ['grading:*', 'score:*', 'feedback:*'],
                'files': ['file:*', 'image:*', 'document:*']
            }
        }
        
        await self.cache_system_manager.initialize(cache_config)
        
        # 5. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥ç®¡ç†å™¨
        print("ğŸ—„ï¸ Setting up Enhanced Database Manager...")
        db_config = {
            'master': {
                'url': 'sqlite+aiosqlite:///./demo_master.db',
                'pool_size': 10,
                'max_overflow': 20
            },
            'replica': {
                'url': 'sqlite+aiosqlite:///./demo_replica.db',
                'pool_size': 15,
                'max_overflow': 25
            }
        }
        self.db_manager = EnhancedConnectionManager(db_config)
        
        # 6. åˆå§‹åŒ–æŸ¥è¯¢ä¼˜åŒ–å™¨
        print("âš¡ Setting up Query Optimizer...")
        optimizer_config = {
            'slow_query_threshold': 0.1,  # 100ms
            'enable_query_cache': True,
            'cache_size': 1000,
            'cache_ttl': 300
        }
        # self.query_optimizer = create_query_optimizer(optimizer_config)
        
        print("âœ… Multi-Layer Cache Architecture Initialized!")
        
    async def demonstrate_cache_hierarchy(self):
        """æ¼”ç¤ºç¼“å­˜å±‚æ¬¡ç»“æ„"""
        print("\nğŸ” Demonstrating Cache Hierarchy...")
        
        test_data = {
            'user_123': {
                'id': 123,
                'name': 'Test User',
                'email': 'test@example.com',
                'profile': {
                    'avatar': '/images/avatar_123.jpg',
                    'preferences': {
                        'theme': 'dark',
                        'language': 'zh-CN'
                    }
                }
            }
        }
        
        # 1. æ•°æ®å†™å…¥L1ç¼“å­˜
        print("ğŸ“ Writing data to L1 Cache...")
        start_time = time.time()
        self.l1_cache.set('user_data', 'user_123', test_data['user_123'])
        l1_write_time = time.time() - start_time
        print(f"   L1 Write Time: {l1_write_time*1000:.2f}ms")
        
        # 2. æ•°æ®åŒæ­¥åˆ°L2ç¼“å­˜
        print("ğŸŒ Syncing data to L2 Cache...")
        start_time = time.time()
        await self.l2_cache.set('user_123', test_data['user_123'], ttl=600)
        l2_write_time = time.time() - start_time
        print(f"   L2 Write Time: {l2_write_time*1000:.2f}ms")
        
        # 3. é¢„å–åˆ°L3ç¼“å­˜ï¼ˆæ¨¡æ‹Ÿé™æ€èµ„æºï¼‰
        avatar_url = "https://jsonplaceholder.typicode.com/photos/1"
        print("ğŸŒ Prefetching static resources to L3 Cache...")
        start_time = time.time()
        await self.l3_cache.prefetch([avatar_url])
        l3_prefetch_time = time.time() - start_time
        print(f"   L3 Prefetch Time: {l3_prefetch_time*1000:.2f}ms")
        
        # 4. æµ‹è¯•è¯»å–æ€§èƒ½
        print("\nğŸ“Š Testing Read Performance...")
        
        # L1è¯»å–
        start_time = time.time()
        l1_data = self.l1_cache.get('user_data', 'user_123')
        l1_read_time = time.time() - start_time
        print(f"   L1 Read: {l1_read_time*1000:.2f}ms - {'HIT' if l1_data else 'MISS'}")
        
        # L2è¯»å–
        start_time = time.time()
        l2_data = await self.l2_cache.get('user_123')
        l2_read_time = time.time() - start_time
        print(f"   L2 Read: {l2_read_time*1000:.2f}ms - {'HIT' if l2_data else 'MISS'}")
        
        # L3è¯»å–
        start_time = time.time()
        l3_data = await self.l3_cache.get(avatar_url)
        l3_read_time = time.time() - start_time
        print(f"   L3 Read: {l3_read_time*1000:.2f}ms - {'HIT' if l3_data else 'MISS'}")
        
    async def demonstrate_cache_consistency(self):
        """æ¼”ç¤ºç¼“å­˜ä¸€è‡´æ€§"""
        print("\nğŸ”„ Demonstrating Cache Consistency...")
        
        # æ¨¡æ‹Ÿæ•°æ®æ›´æ–°
        updated_data = {
            'id': 123,
            'name': 'Updated User',
            'email': 'updated@example.com',
            'last_modified': datetime.now().isoformat()
        }
        
        # 1. æ›´æ–°æ•°æ®å¹¶è§¦å‘ä¸€è‡´æ€§äº‹ä»¶
        print("ğŸ“ Updating data and triggering consistency events...")
        
        # æ›´æ–°L1ç¼“å­˜
        self.l1_cache.set('user_data', 'user_123', updated_data)
        
        # é€šçŸ¥ä¸€è‡´æ€§ç®¡ç†å™¨
        from services.cache_consistency import CacheEvent
        await self.cache_system_manager.consistency_manager.notify_cache_event(
            'l1_cache', CacheEvent.SET, 'user_123', updated_data
        )
        
        # 2. ç­‰å¾…ä¸€è‡´æ€§ä¼ æ’­
        print("â³ Waiting for consistency propagation...")
        await asyncio.sleep(1)
        
        # 3. éªŒè¯ä¸€è‡´æ€§
        print("âœ… Verifying consistency across cache layers...")
        l1_data = self.l1_cache.get('user_data', 'user_123')
        l2_data = await self.l2_cache.get('user_123')
        
        print(f"   L1 Data: {l1_data.get('name') if l1_data else 'None'}")
        print(f"   L2 Data: {l2_data.get('name') if l2_data else 'None'}")
        
    async def demonstrate_performance_monitoring(self):
        """æ¼”ç¤ºæ€§èƒ½ç›‘æ§"""
        print("\nğŸ“ˆ Demonstrating Performance Monitoring...")
        
        # ç”Ÿæˆä¸€äº›æµ‹è¯•è´Ÿè½½
        print("ğŸ”„ Generating test load...")
        
        tasks = []
        for i in range(100):
            # éšæœºè¯»å†™æ“ä½œ
            if i % 3 == 0:
                # L1è¯»å–
                task = asyncio.create_task(self._test_l1_operation(f"test_key_{i}"))
            elif i % 3 == 1:
                # L2è¯»å–
                task = asyncio.create_task(self._test_l2_operation(f"test_key_{i}"))
            else:
                # L3è¯»å–
                task = asyncio.create_task(self._test_l3_operation())
                
            tasks.append(task)
            
        # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        await asyncio.gather(*tasks, return_exceptions=True)
        
        # è·å–æ€§èƒ½æŠ¥å‘Š
        print("\nğŸ“Š Performance Report:")
        system_status = self.cache_system_manager.get_system_status()
        
        print(f"ğŸ“‹ System Status:")
        print(json.dumps(system_status, indent=2, default=str))
        
        # L1ç¼“å­˜ç»Ÿè®¡
        l1_stats = self.l1_cache.get_cache_stats()
        print(f"\nğŸ“± L1 Cache Stats:")
        for cache_name, stats in l1_stats.items():
            print(f"   {cache_name}: {stats}")
            
        # L2ç¼“å­˜ç»Ÿè®¡
        l2_stats = self.l2_cache.get_stats()
        print(f"\nğŸŒ L2 Cache Stats:")
        print(f"   {json.dumps(l2_stats, indent=2)}")
        
        # L3ç¼“å­˜ç»Ÿè®¡
        l3_stats = self.l3_cache.get_stats()
        print(f"\nğŸŒ L3 Cache Stats:")
        print(f"   {json.dumps(l3_stats, indent=2)}")
        
    async def _test_l1_operation(self, key: str):
        """æµ‹è¯•L1ç¼“å­˜æ“ä½œ"""
        # å†™å…¥
        self.l1_cache.set('user_data', key, {'test': 'data', 'timestamp': time.time()})
        # è¯»å–
        self.l1_cache.get('user_data', key)
        
    async def _test_l2_operation(self, key: str):
        """æµ‹è¯•L2ç¼“å­˜æ“ä½œ"""
        # å†™å…¥
        await self.l2_cache.set(key, {'test': 'data', 'timestamp': time.time()})
        # è¯»å–
        await self.l2_cache.get(key)
        
    async def _test_l3_operation(self):
        """æµ‹è¯•L3ç¼“å­˜æ“ä½œ"""
        test_url = "https://httpbin.org/json"
        try:
            await self.l3_cache.get(test_url)
        except:
            pass  # å¿½ç•¥ç½‘ç»œé”™è¯¯
            
    async def demonstrate_database_optimization(self):
        """æ¼”ç¤ºæ•°æ®åº“ä¼˜åŒ–"""
        print("\nğŸ—„ï¸ Demonstrating Database Optimization...")
        
        try:
            # åˆ›å»ºæµ‹è¯•è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            async with self.db_manager.get_connection(DatabaseRole.MASTER) as conn:
                await conn.execute("""
                    CREATE TABLE IF NOT EXISTS demo_users (
                        id INTEGER PRIMARY KEY,
                        name TEXT NOT NULL,
                        email TEXT UNIQUE NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                await conn.commit()
                
            # æ’å…¥æµ‹è¯•æ•°æ®
            print("ğŸ“ Inserting test data...")
            async with self.db_manager.get_connection(DatabaseRole.MASTER) as conn:
                for i in range(10):
                    await conn.execute(
                        "INSERT OR REPLACE INTO demo_users (id, name, email) VALUES (?, ?, ?)",
                        (i, f"User {i}", f"user{i}@example.com")
                    )
                await conn.commit()
                
            # è¯»å–æ•°æ®ï¼ˆä½¿ç”¨å‰¯æœ¬ï¼‰
            print("ğŸ“– Reading data from replica...")
            async with self.db_manager.get_connection(DatabaseRole.REPLICA) as conn:
                cursor = await conn.execute("SELECT * FROM demo_users LIMIT 5")
                results = await cursor.fetchall()
                print(f"   Found {len(results)} users")
                
            # è·å–è¿æ¥æ± çŠ¶æ€
            pool_status = self.db_manager.get_pool_status()
            print(f"\nğŸ“Š Database Pool Status:")
            print(json.dumps(pool_status, indent=2, default=str))
            
        except Exception as e:
            print(f"âŒ Database operation failed: {str(e)}")
            
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ Cleaning up resources...")
        
        if self.cache_system_manager:
            await self.cache_system_manager.shutdown()
            
        if self.l2_cache:
            await self.l2_cache.__aexit__(None, None, None)
            
        if self.l3_cache:
            await self.l3_cache.__aexit__(None, None, None)
            
        if self.db_manager:
            await self.db_manager.close_all()
            
        print("âœ… Cleanup completed!")

async def run_demo():
    """è¿è¡Œæ¼”ç¤º"""
    demo = MultiLayerCacheDemo()
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        await demo.initialize_system()
        
        # æ¼”ç¤ºå„ä¸ªåŠŸèƒ½
        await demo.demonstrate_cache_hierarchy()
        await demo.demonstrate_cache_consistency()
        await demo.demonstrate_performance_monitoring()
        await demo.demonstrate_database_optimization()
        
        print("\nğŸ‰ Multi-Layer Cache Architecture Demo Completed Successfully!")
        
    except Exception as e:
        print(f"âŒ Demo failed: {str(e)}")
        logger.exception("Demo error")
        
    finally:
        await demo.cleanup()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ Smart Reading 3.0 Multi-Layer Cache Architecture Demo")
    print("=" * 80)
    print()
    print("This demo showcases:")
    print("âœ… L1 Application Cache (LRU + Memory)")
    print("âœ… L2 Distributed Cache (Redis with smart invalidation)")
    print("âœ… L3 Edge Cache (CDN and static resource optimization)")
    print("âœ… Cache Consistency Management")
    print("âœ… Performance Monitoring and Analytics")
    print("âœ… Database Connection Pool Optimization")
    print("âœ… Query Optimization and Caching")
    print()
    
    try:
        asyncio.run(run_demo())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Demo interrupted by user")
    except Exception as e:
        print(f"\nâŒ Demo failed: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()