#!/usr/bin/env python3
"""
Performance Optimization and Service Decoupling Demo
æ™ºé˜…3.0æ€§èƒ½ä¼˜åŒ–å’ŒæœåŠ¡è§£è€¦æ¼”ç¤ºå¯åŠ¨è„šæœ¬
"""

import asyncio
import json
import logging
import sys
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from services.service_mesh import ServiceRegistry, ServiceInstance, ServiceDefinition, LoadBalancingStrategy, ServiceMeshClient
from services.async_pipeline import PipelineOrchestrator, TaskDefinition, TaskPriority, PreprocessingProcessor, OCRProcessor, GradingProcessor
from services.fault_tolerance import FaultToleranceManager, CircuitBreakerConfig, RetryConfig, fault_tolerant
from services.apm_monitoring import APMSystem, monitor_performance
from services.service_discovery import ServiceDiscoverySystem, ServiceEndpoint
from services.api_gateway import APIGateway, RouteConfig, RateLimitRule, RateLimitType, AuthRule, AuthType

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PerformanceOptimizationDemo:
    """æ€§èƒ½ä¼˜åŒ–å’ŒæœåŠ¡è§£è€¦æ¼”ç¤º"""
    
    def __init__(self):
        self.service_registry = None
        self.pipeline_orchestrator = None
        self.fault_tolerance_manager = None
        self.apm_system = None
        self.service_discovery = None
        self.api_gateway = None
        
    async def initialize_systems(self):
        """åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿ"""
        print("ğŸš€ Initializing Performance Optimization Systems...")
        
        # 1. åˆå§‹åŒ–æœåŠ¡ç½‘æ ¼
        print("ğŸŒ Setting up Service Mesh...")
        self.service_registry = ServiceRegistry()
        await self.service_registry.start()
        
        # æ³¨å†ŒæœåŠ¡å®šä¹‰
        services = [
            ServiceDefinition(
                service_id="ocr-service",
                name="OCR Processing Service",
                version="2.0.0",
                load_balancing_strategy=LoadBalancingStrategy.LEAST_RESPONSE_TIME
            ),
            ServiceDefinition(
                service_id="grading-service",
                name="AI Grading Service", 
                version="2.0.0",
                load_balancing_strategy=LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN
            ),
            ServiceDefinition(
                service_id="preprocessing-service",
                name="Image Preprocessing Service",
                version="1.0.0",
                load_balancing_strategy=LoadBalancingStrategy.ROUND_ROBIN
            )
        ]
        
        for service_def in services:
            self.service_registry.register_service(service_def)
            
        # æ³¨å†ŒæœåŠ¡å®ä¾‹
        instances = [
            ServiceInstance("ocr-service", "ocr-1", "localhost", 8001, weight=100),
            ServiceInstance("ocr-service", "ocr-2", "localhost", 8002, weight=150),
            ServiceInstance("ocr-service", "ocr-3", "localhost", 8003, weight=200),
            ServiceInstance("grading-service", "grading-1", "localhost", 9001, weight=100),
            ServiceInstance("grading-service", "grading-2", "localhost", 9002, weight=150),
            ServiceInstance("preprocessing-service", "prep-1", "localhost", 7001, weight=100),
        ]
        
        for instance in instances:
            self.service_registry.register_instance(instance)
            
        # 2. åˆå§‹åŒ–å¼‚æ­¥å¤„ç†ç®¡é“
        print("âš™ï¸ Setting up Async Processing Pipeline...")
        self.pipeline_orchestrator = PipelineOrchestrator()
        
        # æ³¨å†Œå¤„ç†å™¨
        self.pipeline_orchestrator.register_processor(PreprocessingProcessor())
        self.pipeline_orchestrator.register_processor(OCRProcessor())
        self.pipeline_orchestrator.register_processor(GradingProcessor())
        
        # å®šä¹‰å¤„ç†ç®¡é“
        from services.async_pipeline import PipelineStage
        self.pipeline_orchestrator.define_pipeline("high_performance_grading", [
            PipelineStage.PREPROCESSING,
            PipelineStage.OCR_PROCESSING,
            PipelineStage.GRADING_ANALYSIS
        ])
        
        await self.pipeline_orchestrator.start()
        
        # 3. åˆå§‹åŒ–å®¹é”™ç®¡ç†
        print("ğŸ›¡ï¸ Setting up Fault Tolerance...")
        self.fault_tolerance_manager = FaultToleranceManager()
        
        # åˆ›å»ºç†”æ–­å™¨
        cb_configs = [
            ("ocr_service", CircuitBreakerConfig(failure_threshold=3, timeout=30.0)),
            ("grading_service", CircuitBreakerConfig(failure_threshold=5, timeout=60.0)),
            ("preprocessing_service", CircuitBreakerConfig(failure_threshold=2, timeout=15.0))
        ]
        
        for name, config in cb_configs:
            self.fault_tolerance_manager.create_circuit_breaker(name, config)
            
        # åˆ›å»ºé‡è¯•å¤„ç†å™¨
        retry_configs = [
            ("ocr_retry", RetryConfig(max_attempts=3, base_delay=1.0)),
            ("grading_retry", RetryConfig(max_attempts=2, base_delay=2.0)),
        ]
        
        for name, config in retry_configs:
            self.fault_tolerance_manager.create_retry_handler(name, config)
            
        # åˆ›å»ºéš”ç¦»èˆ±
        bulkheads = [
            ("ocr_bulkhead", 10),
            ("grading_bulkhead", 8),
            ("preprocessing_bulkhead", 5)
        ]
        
        for name, size in bulkheads:
            self.fault_tolerance_manager.create_bulkhead(name, size)
            
        # 4. åˆå§‹åŒ–APMç³»ç»Ÿ
        print("ğŸ“Š Setting up APM Monitoring...")
        self.apm_system = APMSystem()
        await self.apm_system.start()
        
        # 5. åˆå§‹åŒ–æœåŠ¡å‘ç°
        print("ğŸ” Setting up Service Discovery...")
        self.service_discovery = ServiceDiscoverySystem()
        await self.service_discovery.start()
        
        registry = self.service_discovery.get_registry()
        config_manager = self.service_discovery.get_config_manager()
        
        # æ³¨å†ŒæœåŠ¡ç«¯ç‚¹åˆ°æœåŠ¡å‘ç°
        service_endpoints = [
            ("ocr-service", [
                ServiceEndpoint("ocr-service", "ocr-1", "localhost", 8001),
                ServiceEndpoint("ocr-service", "ocr-2", "localhost", 8002),
                ServiceEndpoint("ocr-service", "ocr-3", "localhost", 8003),
            ]),
            ("grading-service", [
                ServiceEndpoint("grading-service", "grading-1", "localhost", 9001),
                ServiceEndpoint("grading-service", "grading-2", "localhost", 9002),
            ]),
            ("preprocessing-service", [
                ServiceEndpoint("preprocessing-service", "prep-1", "localhost", 7001),
            ])
        ]
        
        for service_name, endpoints in service_endpoints:
            from services.service_discovery import ServiceDefinition as SDServiceDefinition
            service_def = SDServiceDefinition(
                name=service_name,
                version="2.0.0",
                environment="production"
            )
            
            for endpoint in endpoints:
                service_def.add_endpoint(endpoint)
                
            await registry.register_service(service_def)
            
        # è®¾ç½®é…ç½®
        configs = [
            ("performance.max_concurrent_requests", 1000),
            ("performance.request_timeout", 30),
            ("performance.enable_caching", True),
            ("performance.cache_ttl", 300),
            ("monitoring.metrics_enabled", True),
            ("monitoring.tracing_enabled", True),
            ("monitoring.sampling_rate", 1.0),
            ("load_balancing.strategy", "least_response_time"),
            ("circuit_breaker.failure_threshold", 5),
            ("circuit_breaker.timeout", 60)
        ]
        
        for key, value in configs:
            await config_manager.set_configuration(key, value)
            
        # 6. åˆå§‹åŒ–APIç½‘å…³
        print("ğŸŒ‰ Setting up API Gateway...")
        self.api_gateway = APIGateway(host="localhost", port=8080)
        
        # æ·»åŠ è·¯ç”±
        routes = [
            RouteConfig(
                path="/api/v2/ocr/*",
                methods=["POST"],
                upstream="http://localhost:8001",
                strip_path=True,
                add_headers={"X-Service": "OCR-v2", "X-Version": "2.0.0"}
            ),
            RouteConfig(
                path="/api/v2/grading/*", 
                methods=["POST"],
                upstream="http://localhost:9001",
                strip_path=True,
                add_headers={"X-Service": "Grading-v2", "X-Version": "2.0.0"}
            ),
            RouteConfig(
                path="/api/v2/preprocessing/*",
                methods=["POST"],
                upstream="http://localhost:7001",
                strip_path=True,
                add_headers={"X-Service": "Preprocessing-v1"}
            ),
            RouteConfig(
                path="/health",
                methods=["GET"],
                upstream="http://localhost:8080",
                auth_required=False,
                rate_limit_enabled=False
            ),
            RouteConfig(
                path="/metrics",
                methods=["GET"],
                upstream="http://localhost:8080",
                auth_required=False,
                rate_limit_enabled=False
            )
        ]
        
        for route in routes:
            self.api_gateway.add_route(route)
            
        # è®¾ç½®é«˜çº§é™æµè§„åˆ™
        advanced_rate_limits = [
            RateLimitRule(
                name="premium_api_limit",
                limit_type=RateLimitType.PER_API_KEY,
                max_requests=10000,
                window_seconds=3600,
                paths=["/api/v2/*"]
            ),
            RateLimitRule(
                name="ocr_intensive_limit",
                limit_type=RateLimitType.PER_IP,
                max_requests=50,
                window_seconds=60,
                paths=["/api/v2/ocr/*"]
            ),
            RateLimitRule(
                name="grading_burst_limit",
                limit_type=RateLimitType.PER_USER,
                max_requests=20,
                window_seconds=10,
                paths=["/api/v2/grading/*"]
            )
        ]
        
        for rule in advanced_rate_limits:
            self.api_gateway.rate_limiter.add_rule(rule)
            
        # è®¾ç½®é«˜çº§è®¤è¯è§„åˆ™
        auth_rules = [
            AuthRule(
                name="premium_endpoints",
                auth_type=AuthType.JWT,
                paths=["/api/v2/premium/*"],
                required_scopes=["premium", "write"]
            ),
            AuthRule(
                name="standard_api",
                auth_type=AuthType.API_KEY,
                paths=["/api/v2/*"],
                required_scopes=["read", "write"]
            )
        ]
        
        for rule in auth_rules:
            self.api_gateway.authenticator.add_rule(rule)
            
        # æ·»åŠ é«˜çº§APIå¯†é’¥
        api_keys = [
            ("zhiyue_premium_key", "premium_user", ["read", "write", "premium", "admin"]),
            ("zhiyue_standard_key", "standard_user", ["read", "write"]),
            ("zhiyue_readonly_key", "readonly_user", ["read"])
        ]
        
        for key, user, scopes in api_keys:
            self.api_gateway.authenticator.add_api_key(key, user, scopes)
            
        await self.api_gateway.start()
        
        print("âœ… All Systems Initialized Successfully!")
        
    async def demonstrate_service_mesh_performance(self):
        """æ¼”ç¤ºæœåŠ¡ç½‘æ ¼æ€§èƒ½"""
        print("\nğŸŒ Demonstrating Service Mesh Performance...")
        
        client = ServiceMeshClient(self.service_registry)
        
        async with client:
            # å¹¶å‘æœåŠ¡è°ƒç”¨æµ‹è¯•
            print("ğŸ”„ Testing concurrent service calls...")
            
            tasks = []
            for i in range(50):  # 50ä¸ªå¹¶å‘è¯·æ±‚
                task = asyncio.create_task(
                    client.call_service("ocr-service", "/process", "POST", 
                                      {"test_data": f"request_{i}"})
                )
                tasks.append(task)
                
            start_time = time.time()
            results = await asyncio.gather(*tasks, return_exceptions=True)
            duration = time.time() - start_time
            
            successful = len([r for r in results if not isinstance(r, Exception)])
            failed = len(results) - successful
            
            print(f"  ğŸ“Š Results: {successful} successful, {failed} failed in {duration:.2f}s")
            print(f"  âš¡ Throughput: {len(results)/duration:.1f} requests/sec")
            
            # è·å–æœåŠ¡ç»Ÿè®¡
            stats = self.service_registry.get_service_stats()
            print(f"  ğŸ“ˆ Service Stats:")
            for service_id, service_info in stats['services'].items():
                healthy = service_info['healthy_instances']
                total = service_info['total_instances']
                print(f"    {service_id}: {healthy}/{total} healthy instances")
                
    async def demonstrate_pipeline_performance(self):
        """æ¼”ç¤ºç®¡é“æ€§èƒ½"""
        print("\nâš™ï¸ Demonstrating Pipeline Performance...")
        
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_file = Path("./test_performance.jpg")
        test_file.touch()  # åˆ›å»ºç©ºæ–‡ä»¶ç”¨äºæµ‹è¯•
        
        try:
            # æäº¤é«˜ä¼˜å…ˆçº§ç®¡é“ä»»åŠ¡
            print("ğŸš€ Submitting high-priority pipeline tasks...")
            
            pipeline_tasks = []
            for i in range(20):  # 20ä¸ªç®¡é“ä»»åŠ¡
                pipeline_input = {
                    'file_path': str(test_file),
                    'subject': 'math',
                    'answer_key': {'q1': 'A', 'q2': 'B', 'q3': 'C'},
                    'batch_id': f"batch_{i}"
                }
                
                task_ids = await self.pipeline_orchestrator.submit_pipeline(
                    "high_performance_grading", pipeline_input
                )
                pipeline_tasks.extend(task_ids)
                
            print(f"  ğŸ“‹ Submitted {len(pipeline_tasks)} pipeline tasks")
            
            # ç›‘æ§æ‰§è¡Œè¿›åº¦
            completed_count = 0
            start_time = time.time()
            
            while completed_count < len(pipeline_tasks) and time.time() - start_time < 60:
                await asyncio.sleep(2)
                
                new_completed = 0
                for task_id in pipeline_tasks:
                    status = await self.pipeline_orchestrator.get_task_status(task_id)
                    if status and status.status.value in ['completed', 'failed']:
                        new_completed += 1
                        
                if new_completed > completed_count:
                    completed_count = new_completed
                    progress = (completed_count / len(pipeline_tasks)) * 100
                    print(f"  ğŸ“Š Progress: {completed_count}/{len(pipeline_tasks)} ({progress:.1f}%)")
                    
            # è·å–ç®¡é“ç»Ÿè®¡
            pipeline_stats = self.pipeline_orchestrator.get_pipeline_stats()
            print(f"  ğŸ“ˆ Pipeline Stats:")
            print(f"    Average Processing Time: {pipeline_stats['orchestrator_stats']['average_processing_time']:.2f}s")
            print(f"    Completed Tasks: {pipeline_stats['orchestrator_stats']['completed_tasks']}")
            print(f"    Failed Tasks: {pipeline_stats['orchestrator_stats']['failed_tasks']}")
            
        finally:
            if test_file.exists():
                test_file.unlink()
                
    async def demonstrate_fault_tolerance(self):
        """æ¼”ç¤ºå®¹é”™èƒ½åŠ›"""
        print("\nğŸ›¡ï¸ Demonstrating Fault Tolerance...")
        
        # åˆ›å»ºå®¹é”™è£…é¥°çš„æœåŠ¡è°ƒç”¨
        @fault_tolerant(
            circuit_breaker_config=CircuitBreakerConfig(failure_threshold=3, timeout=10.0),
            retry_config=RetryConfig(max_attempts=3, base_delay=0.5),
            bulkhead_size=5
        )
        async def unstable_service_call(failure_rate: float = 0.3):
            """æ¨¡æ‹Ÿä¸ç¨³å®šçš„æœåŠ¡è°ƒç”¨"""
            await asyncio.sleep(0.1)
            
            import random
            if random.random() < failure_rate:
                raise Exception("Service temporarily unavailable")
                
            return {"status": "success", "data": f"processed_at_{time.time()}"}
            
        # æµ‹è¯•æ­£å¸¸æƒ…å†µ
        print("  âœ… Testing normal operation...")
        success_count = 0
        for i in range(20):
            try:
                result = await unstable_service_call(failure_rate=0.1)
                success_count += 1
            except Exception:
                pass
                
        print(f"    Success rate: {success_count}/20 ({success_count/20*100:.1f}%)")
        
        # æµ‹è¯•é«˜å¤±è´¥ç‡
        print("  âš ï¸ Testing high failure rate...")
        success_count = 0
        circuit_breaker_count = 0
        
        for i in range(30):
            try:
                result = await unstable_service_call(failure_rate=0.8)
                success_count += 1
            except Exception as e:
                if "circuit breaker" in str(e).lower():
                    circuit_breaker_count += 1
                    
        print(f"    Success rate: {success_count}/30 ({success_count/30*100:.1f}%)")
        print(f"    Circuit breaker triggers: {circuit_breaker_count}")
        
        # è·å–ç³»ç»Ÿå¥åº·çŠ¶å†µ
        health = self.fault_tolerance_manager.get_system_health()
        print(f"  ğŸ¥ System Health: {health['overall_health']}")
        
    async def demonstrate_monitoring(self):
        """æ¼”ç¤ºç›‘æ§ç³»ç»Ÿ"""
        print("\nğŸ“Š Demonstrating APM Monitoring...")
        
        # åˆ›å»ºç›‘æ§è£…é¥°çš„å‡½æ•°
        @monitor_performance("demo_operation", "demo_service")
        async def monitored_operation(complexity: str = "simple"):
            """è¢«ç›‘æ§çš„æ“ä½œ"""
            if complexity == "simple":
                await asyncio.sleep(0.1)
            elif complexity == "medium":
                await asyncio.sleep(0.5)
            else:  # complex
                await asyncio.sleep(1.0)
                
            return {"result": f"completed_{complexity}_operation"}
            
        # è®¾ç½®APMå®ä¾‹åˆ°å‡½æ•°ä¸Š
        monitored_operation._apm_instance = self.apm_system
        
        # ç”Ÿæˆç›‘æ§æ•°æ®
        print("  ğŸ“ˆ Generating monitoring data...")
        
        operations = ["simple"] * 30 + ["medium"] * 15 + ["complex"] * 5
        
        tasks = []
        for i, complexity in enumerate(operations):
            task = asyncio.create_task(monitored_operation(complexity))
            tasks.append(task)
            
            if i % 10 == 0:  # æ¯10ä¸ªä»»åŠ¡æš‚åœä¸€ä¸‹
                await asyncio.sleep(0.1)
                
        results = await asyncio.gather(*tasks, return_exceptions=True)
        successful = len([r for r in results if not isinstance(r, Exception)])
        
        print(f"    Executed {len(results)} operations, {successful} successful")
        
        # ç­‰å¾…æŒ‡æ ‡æ”¶é›†
        await asyncio.sleep(2)
        
        # è·å–ç›‘æ§æ•°æ®
        dashboard_data = self.apm_system.get_dashboard_data()
        overview = dashboard_data['overview']
        
        print(f"  ğŸ“Š Monitoring Overview:")
        print(f"    Total Metrics: {overview['metrics_summary']['total_metrics']}")
        print(f"    Active Traces: {overview['trace_summary']['active_traces']}")
        print(f"    Completed Traces: {overview['trace_summary']['completed_traces']}")
        print(f"    System Health: Good" if overview['active_alerts'] == 0 else f"Alerts: {overview['active_alerts']}")
        
    async def demonstrate_service_discovery(self):
        """æ¼”ç¤ºæœåŠ¡å‘ç°"""
        print("\nğŸ” Demonstrating Service Discovery...")
        
        client = self.service_discovery.get_client()
        config_manager = self.service_discovery.get_config_manager()
        
        # æœåŠ¡å‘ç°æµ‹è¯•
        print("  ğŸ” Testing service discovery...")
        
        services_to_discover = ["ocr-service", "grading-service", "preprocessing-service"]
        
        for service_name in services_to_discover:
            service = await client.discover(service_name)
            if service:
                healthy_endpoints = service.get_healthy_endpoints()
                print(f"    {service_name}: {len(healthy_endpoints)} healthy endpoints")
            else:
                print(f"    {service_name}: not found")
                
        # é…ç½®ç®¡ç†æµ‹è¯•
        print("  âš™ï¸ Testing configuration management...")
        
        # åŠ¨æ€æ›´æ–°é…ç½®
        await config_manager.set_configuration("performance.max_concurrent_requests", 2000)
        await config_manager.set_configuration("monitoring.sampling_rate", 0.5)
        
        # è¯»å–é…ç½®
        max_requests = client.get_config("performance.max_concurrent_requests")
        sampling_rate = client.get_config("monitoring.sampling_rate")
        caching_enabled = client.get_config("performance.enable_caching")
        
        print(f"    Max concurrent requests: {max_requests}")
        print(f"    Sampling rate: {sampling_rate}")
        print(f"    Caching enabled: {caching_enabled}")
        
        # è·å–ç³»ç»ŸçŠ¶æ€
        status = self.service_discovery.get_system_status()
        print(f"  ğŸ“ˆ Discovery System: {status['services_count']} services, {status['configurations_count']} configs")
        
    async def demonstrate_api_gateway_performance(self):
        """æ¼”ç¤ºAPIç½‘å…³æ€§èƒ½"""
        print("\nğŸŒ‰ Demonstrating API Gateway Performance...")
        
        print("  ğŸš€ API Gateway is running on http://localhost:8080")
        print("  ğŸ“‹ Available endpoints:")
        print("    POST /api/v2/ocr/* (API Key: zhiyue_premium_key)")
        print("    POST /api/v2/grading/* (API Key: zhiyue_standard_key)")
        print("    GET  /health (no auth)")
        print("    GET  /metrics (no auth)")
        
        # è·å–ç½‘å…³ç»Ÿè®¡
        stats = self.api_gateway.get_stats()
        print(f"  ğŸ“Š Gateway Stats:")
        print(f"    Routes: {stats['routes_count']}")
        print(f"    Total Requests: {stats['stats']['total_requests']}")
        print(f"    Success Rate: {stats['stats']['successful_requests']}/{stats['stats']['total_requests']}")
        if stats['stats']['average_response_time'] > 0:
            print(f"    Avg Response Time: {stats['stats']['average_response_time']*1000:.2f}ms")
            
        print("\n  ğŸ’¡ Test the gateway with:")
        print("    curl -H 'X-API-Key: zhiyue_premium_key' -X POST http://localhost:8080/api/v2/ocr/process")
        print("    curl http://localhost:8080/health")
        
    async def get_comprehensive_performance_report(self):
        """è·å–ç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        print("\nğŸ“ˆ Comprehensive Performance Report")
        print("=" * 50)
        
        # æœåŠ¡ç½‘æ ¼ç»Ÿè®¡
        service_stats = self.service_registry.get_service_stats()
        print(f"ğŸŒ Service Mesh:")
        print(f"  Services: {service_stats['total_services']}")
        print(f"  Instances: {service_stats['total_instances']}")
        
        # ç®¡é“ç»Ÿè®¡
        pipeline_stats = self.pipeline_orchestrator.get_pipeline_stats()
        print(f"\nâš™ï¸ Processing Pipeline:")
        print(f"  Completed Tasks: {pipeline_stats['orchestrator_stats']['completed_tasks']}")
        print(f"  Failed Tasks: {pipeline_stats['orchestrator_stats']['failed_tasks']}")
        print(f"  Running Tasks: {pipeline_stats['running_tasks']}")
        print(f"  Avg Processing Time: {pipeline_stats['orchestrator_stats']['average_processing_time']:.2f}s")
        
        # å®¹é”™ç»Ÿè®¡
        ft_health = self.fault_tolerance_manager.get_system_health()
        print(f"\nğŸ›¡ï¸ Fault Tolerance:")
        print(f"  Overall Health: {ft_health['overall_health']}")
        print(f"  Circuit Breakers: {len(ft_health['circuit_breakers'])}")
        
        # ç›‘æ§ç»Ÿè®¡
        apm_overview = self.apm_system.get_system_overview()
        print(f"\nğŸ“Š APM Monitoring:")
        print(f"  Total Metrics: {apm_overview['metrics_summary']['total_metrics']}")
        print(f"  Active Traces: {apm_overview['trace_summary']['active_traces']}")
        print(f"  System Status: {apm_overview['status']}")
        
        # æœåŠ¡å‘ç°ç»Ÿè®¡
        sd_status = self.service_discovery.get_system_status()
        print(f"\nğŸ” Service Discovery:")
        print(f"  Registered Services: {sd_status['services_count']}")
        print(f"  Configurations: {sd_status['configurations_count']}")
        
        # APIç½‘å…³ç»Ÿè®¡
        gateway_stats = self.api_gateway.get_stats()
        print(f"\nğŸŒ‰ API Gateway:")
        print(f"  Total Requests: {gateway_stats['stats']['total_requests']}")
        print(f"  Success Rate: {gateway_stats['stats']['successful_requests']}/{gateway_stats['stats']['total_requests']}")
        print(f"  Blocked Requests: {gateway_stats['stats']['blocked_requests']}")
        if gateway_stats['stats']['average_response_time'] > 0:
            print(f"  Avg Response Time: {gateway_stats['stats']['average_response_time']*1000:.2f}ms")
            
        print("\n" + "=" * 50)
        print("ğŸ‰ Performance Optimization Demo Completed Successfully!")
        
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ Cleaning up resources...")
        
        if self.api_gateway:
            await self.api_gateway.stop()
            
        if self.service_discovery:
            await self.service_discovery.stop()
            
        if self.apm_system:
            await self.apm_system.stop()
            
        if self.pipeline_orchestrator:
            await self.pipeline_orchestrator.stop()
            
        if self.service_registry:
            await self.service_registry.stop()
            
        print("âœ… Cleanup completed!")

async def run_performance_demo():
    """è¿è¡Œæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º"""
    demo = PerformanceOptimizationDemo()
    
    try:
        # åˆå§‹åŒ–æ‰€æœ‰ç³»ç»Ÿ
        await demo.initialize_systems()
        
        # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        print("\nâ³ Waiting for systems to stabilize...")
        await asyncio.sleep(5)
        
        # æ¼”ç¤ºå„ä¸ªåŠŸèƒ½
        await demo.demonstrate_service_mesh_performance()
        await demo.demonstrate_pipeline_performance()
        await demo.demonstrate_fault_tolerance()
        await demo.demonstrate_monitoring()
        await demo.demonstrate_service_discovery()
        await demo.demonstrate_api_gateway_performance()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        await demo.get_comprehensive_performance_report()
        
        # ä¿æŒAPIç½‘å…³è¿è¡Œä»¥ä¾›æµ‹è¯•
        print("\nğŸš€ Systems are running. API Gateway available at http://localhost:8080")
        print("Press Ctrl+C to shutdown...")
        
        try:
            while True:
                await asyncio.sleep(10)
                # å®šæœŸè¾“å‡ºç®€è¦ç»Ÿè®¡
                gateway_stats = demo.api_gateway.get_stats()
                if gateway_stats['stats']['total_requests'] > 0:
                    print(f"ğŸ“Š Gateway: {gateway_stats['stats']['total_requests']} total requests, "
                          f"{gateway_stats['stats']['successful_requests']} successful")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Shutting down systems...")
        
    except Exception as e:
        print(f"âŒ Demo failed: {str(e)}")
        logger.exception("Demo error")
    finally:
        await demo.cleanup()

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸš€ Smart Reading 3.0 Performance Optimization & Service Decoupling Demo")
    print("=" * 80)
    print()
    print("This comprehensive demo showcases:")
    print("âœ… Service Mesh Architecture with Load Balancing")
    print("âœ… Async Processing Pipeline for OCR and Grading")
    print("âœ… Circuit Breaker and Fault Tolerance Patterns")
    print("âœ… Comprehensive Performance Monitoring (APM)")
    print("âœ… Service Discovery and Configuration Management")
    print("âœ… API Gateway with Rate Limiting and Authentication")
    print()
    print("ğŸ¯ Key Performance Features:")
    print("â€¢ Multi-instance load balancing with health checks")
    print("â€¢ High-throughput async pipeline processing")
    print("â€¢ Circuit breaker protection and auto-recovery")
    print("â€¢ Real-time performance monitoring and alerting")
    print("â€¢ Dynamic service discovery and configuration")
    print("â€¢ Advanced API gateway with security and rate limiting")
    print()
    
    try:
        asyncio.run(run_performance_demo())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Demo interrupted by user")
    except Exception as e:
        print(f"\nâŒ Demo failed: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main()